{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNGr_iNapcg6"
      },
      "outputs": [],
      "source": [
        "def get_token(account_name, account_password, secret_key):\n",
        "    url = \"https://api.caresmartz360.com/authorization/signin\"\n",
        "    payload = {\n",
        "        \"accountName\": account_name,\n",
        "        \"accountPassword\": account_password,\n",
        "        \"secretKey\": secret_key\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, json=payload)\n",
        "        response.raise_for_status()\n",
        "        token = response.json().get(\"content\", {}).get(\"token\")\n",
        "        if not token:\n",
        "            raise ValueError(\"Token not found in response\")\n",
        "        return token\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        if response.status_code == 401:\n",
        "            raise RuntimeError(\"Unauthorized: Invalid account credentials. Please verify your account details.\") from http_err\n",
        "        else:\n",
        "            raise RuntimeError(f\"HTTP error occurred while obtaining token: {http_err}\") from http_err\n",
        "    except requests.exceptions.RequestException as req_err:\n",
        "        raise RuntimeError(f\"Request error occurred while obtaining token: {req_err}\") from req_err\n",
        "    except ValueError as json_err:\n",
        "        raise RuntimeError(f\"JSON decode error or missing token: {json_err}\") from json_err"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75duzRRpp0sC"
      },
      "outputs": [],
      "source": [
        "def fetch_churn_data(token, agency_id):\n",
        "    url = \"https://api.caresmartz360.com/cs360/caregiverchurn_v1\"\n",
        "    headers = {\n",
        "        \"agencyId\": f\"{agency_id}\",\n",
        "        \"Authorization\": f\"Bearer {token}\"\n",
        "    }\n",
        "    body = [\n",
        "        {\n",
        "            \"Key\": \"lastModifiedDate\",\n",
        "            \"Value\": None\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=body)\n",
        "        response.raise_for_status()  # Raises HTTPError for bad responses (4xx and 5xx)\n",
        "        return response.json()\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        if response.status_code == 401:\n",
        "            raise RuntimeError(\"Unauthorized: Invalid token or token expired. Please check your credentials.\") from http_err\n",
        "        elif response.status_code == 504:\n",
        "            raise RuntimeError(\"Gateway Timeout: The server did not respond in time. Please try again later.\") from http_err\n",
        "        else:\n",
        "            raise RuntimeError(f\"HTTP error occurred: {http_err}\") from http_err\n",
        "    except requests.exceptions.RequestException as req_err:\n",
        "        raise RuntimeError(f\"Request error occurred: {req_err}\") from req_err\n",
        "    except ValueError as json_err:\n",
        "        raise RuntimeError(f\"JSON decode error occurred: {json_err}\") from json_err\n",
        "\n",
        "def fetch_caregiver_data(token, agency_id):\n",
        "    url = \"https://api.caresmartz360.com/cs360/caregivers_v1\"\n",
        "    headers = {\n",
        "        \"agencyId\": f\"{agency_id}\",\n",
        "        \"Authorization\": f\"Bearer {token}\"\n",
        "    }\n",
        "    body = [\n",
        "        {\n",
        "            \"Key\": \"lastModifiedDate\",\n",
        "            \"Value\": None\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=body)\n",
        "        response.raise_for_status()  # Raises HTTPError for bad responses (4xx and 5xx)\n",
        "        return response.json()\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        if response.status_code == 401:\n",
        "            raise RuntimeError(\"Unauthorized: Invalid token or token expired. Please check your credentials.\") from http_err\n",
        "        elif response.status_code == 504:\n",
        "            raise RuntimeError(\"Gateway Timeout: The server did not respond in time. Please try again later.\") from http_err\n",
        "        else:\n",
        "            raise RuntimeError(f\"HTTP error occurred: {http_err}\") from http_err\n",
        "    except requests.exceptions.RequestException as req_err:\n",
        "        raise RuntimeError(f\"Request error occurred: {req_err}\") from req_err\n",
        "    except ValueError as json_err:\n",
        "        raise RuntimeError(f\"JSON decode error occurred: {json_err}\") from json_err\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MAP16AspnJH"
      },
      "outputs": [],
      "source": [
        "def get_data(agency_id, account_name, account_password, secret_key):\n",
        "    token = get_token(account_name, account_password, secret_key)\n",
        "    if token:\n",
        "        try:\n",
        "            churn_data = fetch_churn_data(token, agency_id)\n",
        "            caregiver_data = fetch_caregiver_data(token, agency_id)\n",
        "            if churn_data is None or caregiver_data is None:\n",
        "                raise ValueError(\"Failed to fetch one or more data sets.\")\n",
        "            return churn_data, caregiver_data\n",
        "        except ValueError as val_err:\n",
        "            raise RuntimeError(f\"Value error: {val_err}\") from val_err\n",
        "        except Exception as ex:\n",
        "            raise RuntimeError(f\"An unexpected error occurred: {ex}\") from ex\n",
        "    else:\n",
        "        raise ValueError(\"Failed to obtain token, Authorization Failed.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UC_S6TtGrGjp"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "def convert_to_df(data):\n",
        "    \"\"\"\n",
        "    Converts the API response data into a Pandas DataFrame.\n",
        "\n",
        "    Checks if the response has the expected structure and handles cases where it doesn't.\n",
        "    \"\"\"\n",
        "    if isinstance(data, list) and len(data) > 0 and isinstance(data[0], dict) and 'content' in data[0]:\n",
        "        content_data = data[0]['content']\n",
        "        content_list = json.loads(content_data)\n",
        "        return pd.DataFrame(content_list)\n",
        "    else:\n",
        "\n",
        "        print(\"Data does not have expected structure. Returning empty DataFrame.\")\n",
        "        return pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikQ1m3PYqBLw",
        "outputId": "a333d9d2-017b-44c1-8c86-fc01b6005971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data does not have expected structure. Returning empty DataFrame.\n",
            "Skipping merge for agency_id 110 due to empty DataFrame(s).\n",
            "Data does not have expected structure. Returning empty DataFrame.\n",
            "Skipping merge for agency_id 148 due to empty DataFrame(s).\n",
            "Data does not have expected structure. Returning empty DataFrame.\n",
            "Skipping merge for agency_id 203 due to empty DataFrame(s).\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "agency_ids = [141,188,110,126,148,203,130,230,297]\n",
        "all_merged_dfs = []\n",
        "for agency_id in agency_ids:\n",
        "\n",
        "  churn_data, caregiver_data = get_data(agency_id, \"CS_Caresmartz_AI\", \"Caresmartz@AI!\", \"Q2FyZXNtYXJ0ejM2MF9DU19DYXJlc21hcnR6X0FJ\")\n",
        "\n",
        "\n",
        "  churn_df_new = convert_to_df(churn_data)\n",
        "\n",
        "\n",
        "  caregiver_df_new = convert_to_df(caregiver_data)\n",
        "\n",
        "  if churn_df_new.empty or caregiver_df_new.empty:\n",
        "      print(f\"Skipping merge for agency_id {agency_id} due to empty DataFrame(s).\")\n",
        "      continue\n",
        "\n",
        "\n",
        "  merged_df = pd.merge(churn_df_new, caregiver_df_new, on='CaregiverId', how='inner')\n",
        "\n",
        "  all_merged_dfs.append(merged_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i0U5_dnrqCl"
      },
      "outputs": [],
      "source": [
        "final_merged_df = pd.concat(all_merged_dfs, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged_df.to_csv(\"final_df.csv\")"
      ],
      "metadata": {
        "id": "Xo4-Pt5df9fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsEHQVepNERb",
        "outputId": "995bd4ff-f9e2-4c84-abb3-615b28960ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(299655, 58)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkCtSMGrluBP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.unwanted_features = [\n",
        "            'Termination Date', 'ScheduleSlotId', 'Address2', 'Caregiver Restriction',\n",
        "            'Caregiver Attributes', 'Skille Type', 'Marital Status',\n",
        "            'EducationalBackGround', 'Date Of Separation', 'SeparationReason',\n",
        "            'SeparationNotes'\n",
        "        ]\n",
        "        self.race_mode = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if 'Race' in X.columns and X['Race'].isnull().mean() * 100 < 40:\n",
        "            self.race_mode = X['Race'].mode()[0]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        X = X.drop(self.unwanted_features, axis=1, errors='ignore')\n",
        "        if 'Race' in X.columns:\n",
        "            X['Race'] = X['Race'].fillna(self.race_mode)\n",
        "        return X\n",
        "\n",
        "\n",
        "class FillNaWithModeTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        categorical_columns = X.select_dtypes(include=['object', 'category']).columns\n",
        "        for column in categorical_columns:\n",
        "            if X[column].isnull().mean() * 100 <= 40:\n",
        "                mode_value = X[column].mode()[0]\n",
        "                X[column] = X[column].fillna(mode_value)\n",
        "        return X\n",
        "\n",
        "\n",
        "class FillNumericalBasedOnSkew(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, skew_threshold=0.5):\n",
        "        self.skew_threshold = skew_threshold\n",
        "        self.fill_values_ = {}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "        for col in numeric_cols:\n",
        "            if X[col].isnull().mean() * 100 <= 40 and X[col].isnull().any():\n",
        "                skewness = X[col].skew()\n",
        "                self.fill_values_[col] = X[col].median() if abs(skewness) > self.skew_threshold else X[col].mean()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        for col, fill_value in self.fill_values_.items():\n",
        "            X[col] = X[col].fillna(fill_value)\n",
        "        return X\n",
        "\n",
        "\n",
        "class FeatureCalculator(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.label_encoders = {\n",
        "            'Gender': LabelEncoder(),\n",
        "            'Race': LabelEncoder()\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if 'Gender' in X.columns:\n",
        "            self.label_encoders['Gender'].fit(X['Gender'].dropna())\n",
        "        if 'Race' in X.columns:\n",
        "            self.label_encoders['Race'].fit(X['Race'].dropna())\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        df = X.copy()\n",
        "        # Convert to datetime\n",
        "        for col in ['Date Of Birth', 'Date Of Joining']:\n",
        "            if col in df.columns:\n",
        "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "\n",
        "        current_date = pd.to_datetime('today')\n",
        "        df['Age'] = current_date.year - df['Date Of Birth'].dt.year\n",
        "        df['Tenure_days'] = (current_date - df['Date Of Joining']).dt.days\n",
        "\n",
        "        if 'IsCaregiverTerminated' in df.columns:\n",
        "            df['IsCaregiverTerminated'] = np.where(df['IsCaregiverTerminated'] == 'Yes', 1, 0)\n",
        "\n",
        "        if 'Gender' in df.columns:\n",
        "            df['Gender'] = self.label_encoders['Gender'].transform(df['Gender'])\n",
        "\n",
        "        if 'Race' in df.columns:\n",
        "            df['Race'] = df['Race'].fillna('Unknown')\n",
        "            df['Race'] = self.label_encoders['Race'].transform(df['Race'])\n",
        "\n",
        "        # Final selected columns\n",
        "        required_columns = [\n",
        "            'CaregiverId', 'Age', 'Gender', 'Race',\n",
        "            'Tenure_days', 'Pay Rate','Pay Unit','Payroll UnitsWithoutOT','Payroll OTUnits','Total Payroll Amount','IsCaregiverTerminated'\n",
        "        ]\n",
        "\n",
        "        return df[required_columns]\n",
        "\n",
        "\n",
        "class RemoveOutliersTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column='Tenure_days'):\n",
        "        self.column = column\n",
        "        self.lower_bound = None\n",
        "        self.upper_bound = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        Q1 = X[self.column].quantile(0.25)\n",
        "        Q3 = X[self.column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        self.lower_bound = Q1 - 1.5 * IQR\n",
        "        self.upper_bound = Q3 + 1.5 * IQR\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return X[(X[self.column] >= self.lower_bound) & (X[self.column] <= self.upper_bound)]\n",
        "\n",
        "\n",
        "\n",
        "class CaregiverIdEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.id_map = {}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if 'CaregiverId' in X.columns:\n",
        "            unique_ids = X['CaregiverId'].unique()\n",
        "            self.id_map = {id_val: idx for idx, id_val in enumerate(unique_ids)}\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        X = X.copy()\n",
        "        if 'CaregiverId' in X.columns and self.id_map:\n",
        "            X['CaregiverId'] = X['CaregiverId'].map(self.id_map)\n",
        "        return X\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRNTFp7WVei3"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Define pipeline steps\n",
        "full_preprocessing_pipeline = Pipeline([\n",
        "    ('custom_transformer', CustomTransformer()),\n",
        "    ('fill_na_mode', FillNaWithModeTransformer()),\n",
        "    ('fill_numerical', FillNumericalBasedOnSkew()),\n",
        "    ('feature_calculator', FeatureCalculator()),\n",
        "    ('remove_outliers', RemoveOutliersTransformer(column='Tenure_days')),\n",
        "    ('caregiver_id_encoder', CaregiverIdEncoder())\n",
        "])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZfogNURa8em"
      },
      "outputs": [],
      "source": [
        "import traceback\n",
        "\n",
        "def preprocess_dataframe(df):\n",
        "    try:\n",
        "        processed_df = full_preprocessing_pipeline.fit_transform(df)\n",
        "        return processed_df\n",
        "    except Exception as e:\n",
        "        print(\"Pipeline execution failed.\")\n",
        "        traceback.print_exc()\n",
        "        return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df = preprocess_dataframe(final_merged_df)"
      ],
      "metadata": {
        "id": "y4evoEcjUOxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVpkXjZtQEuy",
        "outputId": "3ce4a127-425a-4a27-9357-1e59bbb88a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(285120, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "KmsTuGr6TPdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHEKCjgLwZyu",
        "outputId": "83abb18c-1600-44da-a2c0-fc9adbe3b3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65977, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df['Pay Unit'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "sSEvdE1eiOxH",
        "outputId": "d0503d77-61d0-4d56-f2ea-90a78cc1d205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pay Unit\n",
              "Hourly    65542\n",
              "Visit       435\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pay Unit</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Hourly</th>\n",
              "      <td>65542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Visit</th>\n",
              "      <td>435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df['Pay Unit'] = processed_df['Pay Unit'].map({'Hourly': 0, 'Visit': 1})"
      ],
      "metadata": {
        "id": "4So4pelsiI1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df['Pay Rate'] = processed_df['Pay Rate'].astype(float).astype(int)"
      ],
      "metadata": {
        "id": "Xw7r6OfSpD7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df['Pay Unit'] = processed_df['Pay Unit'].astype(float).astype(int)"
      ],
      "metadata": {
        "id": "T0nCJyX01Ici"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df['Payroll OTUnits'] = processed_df['Payroll OTUnits'].astype(float).astype(int)"
      ],
      "metadata": {
        "id": "A6rhehgGpblY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df['Payroll UnitsWithoutOT'] = processed_df['Payroll UnitsWithoutOT'].astype(float).astype(int)"
      ],
      "metadata": {
        "id": "LlVxsTEDxUz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df['Total Payroll Amount'] = processed_df['Total Payroll Amount'].astype(float).astype(int)"
      ],
      "metadata": {
        "id": "Qdqf65Y7w9Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df.drop(columns=['CaregiverId'], inplace=True)"
      ],
      "metadata": {
        "id": "TcMqM7Fw3ebL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "V1LvKxjY8H8b",
        "outputId": "306eb566-21cb-402c-af38-0191660e2b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                       int32\n",
              "Gender                    int64\n",
              "Race                      int64\n",
              "Tenure_days               int64\n",
              "Pay Rate                  int64\n",
              "Pay Unit                  int64\n",
              "Payroll UnitsWithoutOT    int64\n",
              "Payroll OTUnits           int64\n",
              "Total Payroll Amount      int64\n",
              "IsCaregiverTerminated     int64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>int32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Race</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tenure_days</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pay Rate</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pay Unit</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Payroll UnitsWithoutOT</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Payroll OTUnits</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Payroll Amount</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IsCaregiverTerminated</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCV7IjjM3nli",
        "outputId": "65eb65c8-ff1a-40dc-e9ed-27c9bbee4e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65977, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "\n",
        "# Feature and target split\n",
        "X = processed_df.drop(columns=['IsCaregiverTerminated'])\n",
        "y = processed_df['IsCaregiverTerminated']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define hyperparameter space\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': randint(3, 15),\n",
        "    'learning_rate': uniform(0.01, 0.3),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'colsample_bytree': uniform(0.6, 0.4),\n",
        "    'gamma': uniform(0, 5),\n",
        "    'reg_alpha': uniform(0, 5),\n",
        "    'reg_lambda': uniform(0, 5)\n",
        "}\n",
        "\n",
        "# XGBoost model\n",
        "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Randomized search\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best estimator\n",
        "best_model = random_search.best_estimator_\n",
        "print(\"Best Parameters:\\n\", random_search.best_params_)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Accuracy on test set:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Feature importance\n",
        "feature_imp_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(feature_imp_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs5U6LKoVMN4",
        "outputId": "64ba6d46-b149-494e-82d6-96aaddf36882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [11:52:31] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters:\n",
            " {'colsample_bytree': np.float64(0.9942601816442402), 'gamma': np.float64(1.2102763575575022), 'learning_rate': np.float64(0.21164066422176356), 'max_depth': 13, 'n_estimators': 172, 'reg_alpha': np.float64(1.2107996913871295), 'reg_lambda': np.float64(4.015698781899479), 'subsample': np.float64(0.7881202537784153)}\n",
            "Accuracy on test set: 0.9781752046074568\n",
            "                  Feature  Importance\n",
            "4                Pay Rate    0.186403\n",
            "3             Tenure_days    0.175462\n",
            "2                    Race    0.168933\n",
            "0                     Age    0.162263\n",
            "1                  Gender    0.107792\n",
            "8    Total Payroll Amount    0.060889\n",
            "7         Payroll OTUnits    0.050717\n",
            "6  Payroll UnitsWithoutOT    0.047338\n",
            "5                Pay Unit    0.040204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "\n",
        "X = processed_df.drop(columns=['IsCaregiverTerminated'])\n",
        "y = processed_df['IsCaregiverTerminated']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': randint(3, 15),\n",
        "    'learning_rate': uniform(0.01, 0.3),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'colsample_bytree': uniform(0.6, 0.4),\n",
        "    'num_leaves': randint(20, 150)\n",
        "}\n",
        "\n",
        "lgbm = LGBMClassifier(random_state=42, class_weight='balanced')\n",
        "\n",
        "lgbm_search = RandomizedSearchCV(\n",
        "    estimator=lgbm,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lgbm_search.fit(X_train, y_train)\n",
        "best_lgbm = lgbm_search.best_estimator_\n",
        "print(\"LightGBM Accuracy:\", accuracy_score(y_test, best_lgbm.predict(X_test)))\n",
        "\n",
        "lgbm_feat = pd.DataFrame({'Feature': X.columns, 'Importance': best_lgbm.feature_importances_}).sort_values(by='Importance', ascending=False)\n",
        "print(lgbm_feat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vlmzSOY4VYVl",
        "outputId": "de57f5cb-f508-4959-a4a6-c0433ff1be5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 30887, number of negative: 21894\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010300 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 767\n",
            "[LightGBM] [Info] Number of data points in the train set: 52781, number of used features: 9\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "LightGBM Accuracy: 0.9912094574113368\n",
            "                  Feature  Importance\n",
            "3             Tenure_days        8432\n",
            "0                     Age        6340\n",
            "8    Total Payroll Amount        3243\n",
            "4                Pay Rate        3127\n",
            "2                    Race        1262\n",
            "6  Payroll UnitsWithoutOT        1101\n",
            "1                  Gender         938\n",
            "7         Payroll OTUnits         276\n",
            "5                Pay Unit          23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tJ8ce-UiWoCg",
        "outputId": "35c2262c-8adf-416d-efdd-9c91a492fd76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "X = processed_df.drop(columns=['IsCaregiverTerminated'])\n",
        "y = processed_df['IsCaregiverTerminated']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    'iterations': randint(50, 200),\n",
        "    'depth': randint(3, 10),\n",
        "    'learning_rate': uniform(0.01, 0.3),\n",
        "    'l2_leaf_reg': uniform(1, 10)\n",
        "}\n",
        "\n",
        "cat_model = CatBoostClassifier(verbose=0, random_state=42, auto_class_weights='Balanced')\n",
        "\n",
        "cat_search = RandomizedSearchCV(\n",
        "    estimator=cat_model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "cat_search.fit(X_train, y_train)\n",
        "best_cat = cat_search.best_estimator_\n",
        "print(\"CatBoost Accuracy:\", accuracy_score(y_test, best_cat.predict(X_test)))\n",
        "\n",
        "cat_feat = pd.DataFrame({'Feature': X.columns, 'Importance': best_cat.get_feature_importance()}).sort_values(by='Importance', ascending=False)\n",
        "print(cat_feat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl_ZfUt8WA-G",
        "outputId": "9c9fe647-6539-4638-940c-3287f9dfa4c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "CatBoost Accuracy: 0.9529402849348287\n",
            "                  Feature  Importance\n",
            "3             Tenure_days   37.961371\n",
            "0                     Age   30.383730\n",
            "2                    Race   14.957932\n",
            "4                Pay Rate   10.900931\n",
            "1                  Gender    4.043811\n",
            "8    Total Payroll Amount    0.870562\n",
            "6  Payroll UnitsWithoutOT    0.809901\n",
            "7         Payroll OTUnits    0.047650\n",
            "5                Pay Unit    0.024113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vDRl8BHUd_EM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}